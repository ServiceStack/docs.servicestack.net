<!doctype html>
<html lang="en">
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7722718-13"></script>
    <script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date()); gtag('config', 'UA-7722718-13');</script>
    
    <meta charset="utf-8"/>
    <meta name='date' content='2025-04-23T04:45:05.9393822Z'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" type="image/svg" href="/img/logo.svg">
    <title>Self-host LLMs in production with llama.cpp llama-server</title>
    <script>
    if (location.search === "?dark") localStorage.setItem('color-scheme','dark') 
    if (location.search === "?light") localStorage.removeItem('color-scheme') 
    const cls = document.querySelector('html').classList
    if (localStorage.getItem('color-scheme') === 'dark')
        cls.add('dark')
    else
        cls.remove('dark')
    </script>
    <link rel="stylesheet" href="/css/app.css">
    
    <script type="importmap">
{
    "imports": {
        "app.mjs": "/mjs/app.mjs",
        "vue": "/lib/mjs/vue.mjs",
        "@servicestack/client": "/lib/mjs/servicestack-client.mjs",
        "@servicestack/vue": "/lib/mjs/servicestack-vue.mjs"
    }
}
</script>
</head>
<body class="bg-white dark:bg-black dark:text-white">

<header id="header" class="top-0 fixed z-50 h-14 bg-white dark:bg-black opacity-90 w-full shadow">
  <nav class="border-b border-gray-200 dark:border-gray-700 bg-white dark:bg-black">
    <div class="mx-auto max-w-[100rem] pr-4 sm:pr-6 lg:pr-8">
      <div class="flex h-16 justify-between">
        <div class="flex">
          <div class="flex flex-shrink-0 items-center">
            <a class="mr-2 lg:mr-8 flex items-center" href="/">
                <svg class="w-8 h-8 sm:ml-2 sm:w-12 sm:h-12" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="currentColor" d="M10 6c1.544 1.76 2.276 4.15 2.217 6.61c3.968 1.67 9.924 6.12 11.181 12.39H28C26.051 14.31 14.918 6.77 10 6zm-2 7c4.67 4.913.81 11.582-4 12h18.97C21.5 18.289 11.95 13.533 8 13z"/></svg>
                <span class="hidden sm:block text-2xl font-semibold">Documentation</span>
            </a>
          </div>
            <div class="hidden sm:-my-px sm:ml-6 sm:flex sm:space-x-4 lg:space-x-8">
                <!-- Current: "border-indigo-500 text-gray-900", Default: "border-transparent text-gray-500 hover:border-gray-300 hover:text-gray-700" -->
                        <a href="/templates/" class="inline-flex items-center border-b-2 px-1 pt-1 text-sm font-medium border-transparent text-gray-500 hover:border-gray-300 hover:text-gray-700 dark:hover:text-gray-200">
                            <span class="hidden xl:inline mr-1">Project</span> Templates
                        </a>
                        <a href="/vue/" class="inline-flex items-center border-b-2 px-1 pt-1 text-sm font-medium border-transparent text-gray-500 hover:border-gray-300 hover:text-gray-700 dark:hover:text-gray-200">
                            Vue
                        </a>
                        <a href="/autoquery/" class="inline-flex items-center border-b-2 px-1 pt-1 text-sm font-medium border-transparent text-gray-500 hover:border-gray-300 hover:text-gray-700 dark:hover:text-gray-200">
                            AutoQuery
                        </a>
                        <a href="/auth/" class="inline-flex items-center border-b-2 px-1 pt-1 text-sm font-medium border-transparent text-gray-500 hover:border-gray-300 hover:text-gray-700 dark:hover:text-gray-200">
                            Auth
                        </a>
                        <a href="/ormlite/" class="inline-flex items-center border-b-2 px-1 pt-1 text-sm font-medium border-transparent text-gray-500 hover:border-gray-300 hover:text-gray-700 dark:hover:text-gray-200">
                            OrmLite
                        </a>
                        <a href="/redis/" class="inline-flex items-center border-b-2 px-1 pt-1 text-sm font-medium border-transparent text-gray-500 hover:border-gray-300 hover:text-gray-700 dark:hover:text-gray-200">
                            Redis
                        </a>
                        <a href="/locode/" class="inline-flex items-center border-b-2 px-1 pt-1 text-sm font-medium border-transparent text-gray-500 hover:border-gray-300 hover:text-gray-700 dark:hover:text-gray-200 hidden lg:inline-flex">
                            Locode
                        </a>
                        <a href="/grpc/" class="inline-flex items-center border-b-2 px-1 pt-1 text-sm font-medium border-transparent text-gray-500 hover:border-gray-300 hover:text-gray-700 dark:hover:text-gray-200 hidden lg:inline-flex">
                            gRPC
                        </a>
                        <a href="/ai-server/" class="inline-flex items-center border-b-2 px-1 pt-1 text-sm font-medium border-indigo-500 text-gray-900">
                            AI Server
                        </a>
            </div>
        </div>
        <div class="hidden sm:ml-6 sm:flex sm:items-center">
            <typesense></typesense>
            <dark-mode-toggle class="ml-2 w-10"></dark-mode-toggle>
        </div>
        <div class="-mr-2 flex items-center sm:hidden">
          <!-- Mobile menu button -->
          <button type="button" v-on:click="open=!open" class="inline-flex items-center justify-center rounded-md bg-white dark:bg-black p-2 text-gray-400 hover:bg-gray-100 dark:hover:bg-gray-800 hover:text-gray-500 focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2 dark:ring-offset-black" aria-controls="mobile-menu" aria-expanded="false">
            <span class="sr-only">Open main menu</span>
            <!-- Menu open: "hidden", Menu closed: "block" -->
            <svg :class="['h-6 w-6', open ? 'hidden' : 'block']" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true">
              <path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" />
            </svg>
            <!-- Menu open: "block", Menu closed: "hidden" -->
            <svg :class="['h-6 w-6', open ? 'block' : 'hidden']" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true">
              <path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12" />
            </svg>
          </button>
        </div>
      </div>
    </div>

    <!-- Mobile menu, show/hide based on menu state. -->
    <div v-cloak v-if="open" class="sm:hidden">
        <div class="space-y-1 pb-3 pt-2">
            <!-- Current: "border-indigo-500 bg-indigo-50 text-indigo-700", Default: "border-transparent text-gray-600 hover:border-gray-300 hover:bg-gray-50 hover:text-gray-800" -->
                    <a href="/templates/" class="block border-l-4 py-2 pl-3 pr-4 text-base font-medium border-transparent text-gray-600 dark:text-gray-300 hover:border-gray-300 hover:bg-gray-50 dark:hover:bg-gray-900 hover:text-gray-800 dark:hover:text-gray-100">
                        Project Templates
                    </a>
                    <a href="/vue/" class="block border-l-4 py-2 pl-3 pr-4 text-base font-medium border-transparent text-gray-600 dark:text-gray-300 hover:border-gray-300 hover:bg-gray-50 dark:hover:bg-gray-900 hover:text-gray-800 dark:hover:text-gray-100">
                        Vue
                    </a>
                    <a href="/autoquery/" class="block border-l-4 py-2 pl-3 pr-4 text-base font-medium border-transparent text-gray-600 dark:text-gray-300 hover:border-gray-300 hover:bg-gray-50 dark:hover:bg-gray-900 hover:text-gray-800 dark:hover:text-gray-100">
                        AutoQuery
                    </a>
                    <a href="/auth/" class="block border-l-4 py-2 pl-3 pr-4 text-base font-medium border-transparent text-gray-600 dark:text-gray-300 hover:border-gray-300 hover:bg-gray-50 dark:hover:bg-gray-900 hover:text-gray-800 dark:hover:text-gray-100">
                        Auth
                    </a>
                    <a href="/ormlite/" class="block border-l-4 py-2 pl-3 pr-4 text-base font-medium border-transparent text-gray-600 dark:text-gray-300 hover:border-gray-300 hover:bg-gray-50 dark:hover:bg-gray-900 hover:text-gray-800 dark:hover:text-gray-100">
                        OrmLite
                    </a>
                    <a href="/redis/" class="block border-l-4 py-2 pl-3 pr-4 text-base font-medium border-transparent text-gray-600 dark:text-gray-300 hover:border-gray-300 hover:bg-gray-50 dark:hover:bg-gray-900 hover:text-gray-800 dark:hover:text-gray-100">
                        Redis
                    </a>
                    <a href="/locode/" class="block border-l-4 py-2 pl-3 pr-4 text-base font-medium border-transparent text-gray-600 dark:text-gray-300 hover:border-gray-300 hover:bg-gray-50 dark:hover:bg-gray-900 hover:text-gray-800 dark:hover:text-gray-100">
                        Locode
                    </a>
                    <a href="/grpc/" class="block border-l-4 py-2 pl-3 pr-4 text-base font-medium border-transparent text-gray-600 dark:text-gray-300 hover:border-gray-300 hover:bg-gray-50 dark:hover:bg-gray-900 hover:text-gray-800 dark:hover:text-gray-100">
                        gRPC
                    </a>
                    <a href="/ai-server/" class="block border-l-4 py-2 pl-3 pr-4 text-base font-medium border-indigo-500 bg-indigo-50 dark:bg-indigo-900 text-indigo-700 dark:text-indigo-200">
                        AI Server
                    </a>
        </div>
    </div>
  </nav>
</header>

<script type="module">
import { ref } from "vue"
import { mount } from "app.mjs"

const Header = {
    setup() {
        const open = ref(false)
        return { open }
    }
}
mount('#header', Header)
</script>


<div class="min-h-screen">
    <main role="main" class="pt-16 pb-3 max-w-[100rem] mx-auto">
        

<script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ 
        startOnLoad: true,
        theme: 'base',
        'themeVariables': {
            'primaryColor': '#fff',
            'lineColor': '#333',
            'primaryBorderColor': 'rgb(67 56 202)', // text-indigo-700	
            'secondaryColor': '#fff',
            'primaryTextColor': '#333',
            'tertiaryColor': '#333'
        }        
    });
</script>
<style>
pre.mermaid {
    background-color: #fff !important;
}
.dark pre.mermaid {
    background-color: #000 !important; /*bg-gray-800*/
}
.dark pre.mermaid .edgeLabel, .dark pre.mermaid .edgeLabel p, .dark pre.mermad .labelBkg {
    background-color: #000 !important;
}
.dark pre.mermaid .edgeLabel, .dark pre.mermaid .edgeLabel p {
    color: rgb(209 213 219) !important;
}
.dark pre.mermaid .flowchart-link { 
    stroke: rgb(209 213 219) !important;
}
.dark pre.mermaid .node rect {
    stroke: #fff !important;
}
.dark pre.mermaid .marker.flowchart-v2 {
    stroke: #fff !important;
    fill: #fff !important;
}
</style>

<link rel="stylesheet" href="/css/asciinema-player.css">
<script src="/lib/js/asciinema-player.js"></script>




<style>
.active {
    color: #0ea5e9 !important;
}
</style>
<link rel="stylesheet" href="/css/highlight.css">
<link rel="stylesheet" href="/css/typography.css">
<link rel="stylesheet" href="/css/lite-yt-embed.css">

<div class="w-full max-w-[100rem] mx-auto">
    <div class="flex flex-wrap">
        <div id="sidebar" class="z-40 inset-0 flex-none bg-white dark:bg-black lg:w-64 xl:w-80">
            <button v-cloak v-on:click="open=true" :class="['text-gray-400 hover:text-gray-500 pt-4 pl-2 absolute transform transition-all duration-200', open ? 'opacity-0 translate-x-56' : 'opacity-100']" title="Open Sidebar">
                <svg class="w-6 h-6" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20 12H10m10 0l-4 4m4-4l-4-4M4 4v16"/></svg>
            </button>
            <div :class="['fixed bg-white dark:bg-black h-screen overflow-y-auto scrolling-touch overflow-hidden shadow lg:shadow-none transform transition-transform duration-200', open ? '' : 'translate-x-[-100%]']">
                <nav class="sidebar lg:w-64 xl:w-80 px-1 pt-6 pb-16 overflow-y-auto font-medium text-sm lg:text-base sm:px-3 xl:px-5" aria-label="Sidebar">
                    <close-button title="Close Sidebar" class="lg:hidden -mr-2" v-on:close="open=false"></close-button>
                                <a href="/ai-server/" class="block flex items-center whitespace-nowrap">
<svg class='h-6 w-6 shrink-0 text-sky-500' fill='none' viewBox='0 0 24 24' stroke-width='1.5' stroke='currentColor' aria-hidden='true'><path stroke-linecap='round' stroke-linejoin='round' d='M2.25 12l8.954-8.955c.44-.439 1.152-.439 1.591 0L21.75 12M4.5 9.75v10.125c0 .621.504 1.125 1.125 1.125H9.75v-4.875c0-.621.504-1.125 1.125-1.125h2.25c.621 0 1.125.504 1.125 1.125V21h4.125c.621 0 1.125-.504 1.125-1.125V9.75M8.25 21h8.25'></path></svg>                                    <span class="p-2 pl-3 font-display font-medium text-slate-900 dark:text-white">
AI Server                                    </span>
                                </a>
                        <ul role="list" class="mb-6 mt-2 ml-3 space-y-2 border-l-2 border-slate-100 dark:border-slate-800 lg:mt-4 lg:space-y-4 lg:border-slate-200">
                                <li class="relative">
                                    <a href="/ai-server/quickstart" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Quick Start
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/configuration" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Configuration
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/ollama" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Ollama
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/llama-server" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full active font-semibold text-sky-500 before:bg-sky-500">
                                        llama.cpp llama-server
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/comfy-extension" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        ComfyUI Agent
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/openai-chat-all-languages" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        OpenAI Chat in 11 languages
                                    </a>
                                </li>
                        </ul>
                                <a href="/ai-server/usage" class="block flex items-center whitespace-nowrap">
                                    <span class="p-2 pl-3 font-display font-medium text-slate-900 dark:text-white">
Usage                                    </span>
                                </a>
                        <ul role="list" class="mb-6 mt-2 ml-3 space-y-2 border-l-2 border-slate-100 dark:border-slate-800 lg:mt-4 lg:space-y-4 lg:border-slate-200">
                                <li class="relative">
                                    <a href="/ai-server/chat" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Chat
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/text-to-image" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Text to Image
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/image-to-text" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Image to Text
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/image-to-image" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Image to Image
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/image-with-mask" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Image with Mask
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/image-upscale" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Image Upscale
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/speech-to-text" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Speech to Text
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/text-to-speech" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Text to Speech
                                    </a>
                                </li>
                        </ul>
                                <a href="/ai-server/transform/" class="block flex items-center whitespace-nowrap">
                                    <span class="p-2 pl-3 font-display font-medium text-slate-900 dark:text-white">
Transform                                    </span>
                                </a>
                        <ul role="list" class="mb-6 mt-2 ml-3 space-y-2 border-l-2 border-slate-100 dark:border-slate-800 lg:mt-4 lg:space-y-4 lg:border-slate-200">
                                <li class="relative">
                                    <a href="/ai-server/transform/image" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Image Transforms
                                    </a>
                                </li>
                                <li class="relative">
                                    <a href="/ai-server/transform/video" class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-slate-500 before:hidden before:bg-slate-300 hover:text-slate-600 hover:before:block dark:text-slate-400 dark:before:bg-slate-700 dark:hover:text-slate-300">
                                        Video Transforms
                                    </a>
                                </li>
                        </ul>
                </nav>
            </div>
        </div>
        <div id="doc" class="mx-auto flex">
            <div class="mt-8 mx-auto prose lg:prose-lg">
                
                    <section class="not-prose mb-16 md:mb-12">
                        <h1 class="text-4xl tracking-tight font-extrabold text-gray-900 dark:text-gray-50 sm:text-5xl md:text-6xl">
                            Self-host LLMs in production with llama.cpp llama-server
                        </h1>
                    </section>

                <div class="not-prose"></div>

                <div class="content"><p><a href="https://ollama.com">Ollama</a>, <a href="https://lmstudio.ai">LM Studio</a> and <a href="https://jan.ai">Jan</a>
have become popular choices for AI enthusiasts looking to run large language models
(LLMs) locally which provide a UX-friendly intuitive interfaces for downloading, installing and running a variety of open-source models on personal workstations, acceleratable with GPUs.</p>
<p>However, when scaling beyond personal use, these tools reveal their limitations which weren't
designed with production deployment in mind, often lacking flexible and robust resource
management, fine-grained authorized usage and optimizations necessary for sustained, high-demand
environments.</p>
<h2 id="enter-llama-server-the-production-workhorse">Enter llama-server: The Production workhorse<a class="header-anchor" href="javascript:;" onclick="location.hash='#enter-llama-server-the-production-workhorse'" aria-label="Permalink">&ZeroWidthSpace;</a></h2>
<p>The technology underpinning these applications is
<a href="https://github.com/ggml-org/llama.cpp">llama.cpp</a>, a groundbreaking C/C++ implementation that
enables running sophisticated language models on consumer hardware.
This remarkable project, created by Georgi Gerganov, revolutionized the LLM landscape by making
previously cloud-only models accessible to everyday users through clever quantization techniques
and memory-efficient operations.</p>
<p>While Ollama and LM Studio provide user-friendly wrappers around this technology, llama.cpp's
<a href="https://github.com/ggml-org/llama.cpp/tree/master/examples/server">llama-server</a> leverages the
same core but strips away the overhead to focus exclusively on performance and stability.
By directly utilizing the llama.cpp library and its server component, organizations can bypass the
abstractions introduced by desktop applications and tap into the raw power of the underlying engine whose
<a href="https://github.com/ggml-org/llama.cpp/tree/master/examples/server#usage">highly configurable runtime</a>
allows for optimized self-hosting of authorized models.</p>
<p>This direct approach eliminates unnecessary layers that might introduce latency or unexpected
behaviors, providing a more consistent and predictable experience necessary for production environments.
For DevOps teams and system administrators, this translates to fewer surprises during deployment
and operation — a crucial factor when incorporating self-hosting AI solutions into critical business applications.</p>
<h2 id="hosting-llama-server-with-docker">Hosting llama-server with Docker<a class="header-anchor" href="javascript:;" onclick="location.hash='#hosting-llama-server-with-docker'" aria-label="Permalink">&ZeroWidthSpace;</a></h2>
<p>Organizations that have incorporated container based deployment solutions will most likely prefer
a docker solution of which is available in a number of different hardware optimized configurations including CPU, CUDA for NVIDIA GPUs, ROCm for AMD GPUs and MUSA for Moore Threads GPUs.</p>
<p>Docker containers requiring NVIDIA GPU accelearation will require installing the
<a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">NVidia Container Toolkit</a> which allows you to run the <code>llama.cpp:server-cuda</code> CUDA optimized image with the <code>--gpus</code> flag to utilize your hardwares NVIDIA GPUs, e.g:</p>
<pre><code class="language-sh">docker run -p 8080:8080 -v /path/to/models:/models --gpus all \
    ghcr.io/ggml-org/llama.cpp:server-cuda -m models/phi-4.Q4_K_M.gguf \
    -c 512 --host 0.0.0.0 --port 8080 --n-gpu-layers 999
</code></pre>
<p>llama.cpp can run models in the <a href="https://github.com/ggml-org/ggml/blob/master/docs/gguf.md">GGUF File format</a> that are commonly <a href="https://huggingface.co/models?library=gguf&amp;sort=trending">hosted on hugging face</a>. As of this writing Microsoft, Google and Mistral AI have released some of the best quantized LLMs you can run on consumer GPUs:</p>
<ul>
<li><a href="https://huggingface.co/bartowski/phi-4-GGUF/tree/main">Phi-4 14B</a> by Microsoft</li>
<li><a href="https://huggingface.co/google/gemma-3-27b-it-qat-q4_0-gguf/tree/main">Gemma3 27B</a> by Google</li>
<li><a href="https://huggingface.co/openfree/Mistral-Small-3.1-24B-Instruct-2503-Q8_0-GGUF/tree/main">Mistral Small 3.1 24B</a> by Mistral AI</li>
</ul>
<h3 id="docker-compose">Docker compose<a class="header-anchor" href="javascript:;" onclick="location.hash='#docker-compose'" aria-label="Permalink">&ZeroWidthSpace;</a></h3>
<p>Docker compose is a great solution for hosting llama-server in production environments which simplifies managing multiple services within declarative configurations, making deployments more repeatable and scalable.</p>
<pre><code class="language-yml">version: '3'

services:
  phi:
    image: ghcr.io/ggml-org/llama.cpp:server-cuda
    environment:
      - LLAMA_ARG_N_GPU_LAYERS=999
      - LLAMA_ARG_MODEL=/models/phi-4.Q4_K_M.gguf
    ports:
      - &quot;8000:8080&quot;
    volumes:
      - ./models:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  gemma:
    image: ghcr.io/ggml-org/llama.cpp:server-cuda
    environment:
      - LLAMA_ARG_N_GPU_LAYERS=999
      - LLAMA_ARG_MODEL=/models/gemma-3-27b-it-qat-q4_0-gguf
    ports:
      - &quot;8001:8080&quot;
    volumes:
      - ./models:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  mistral:
    image: ghcr.io/ggml-org/llama.cpp:server-cuda
    environment:
      - LLAMA_ARG_N_GPU_LAYERS=999
      - LLAMA_ARG_MODEL=/models/mistral-small-3.1-24b-instruct-2503-q8_0.gguf
    ports:
      - &quot;8002:8080&quot;
    volumes:
      - ./models:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
</code></pre>
<p>After saving this to <code>docker-compose.yml</code> along with the models:</p>
<div class="language-files"><div class="ml-6">
  <div class="flex items-center text-base leading-8">
    <svg class="mr-1 text-slate-600 inline-block select-none align-text-bottom overflow-visible" aria-hidden="true" focusable="false" role="img" viewBox="0 0 12 12" width="12" height="12" fill="currentColor"><path d="M6 8.825c-.2 0-.4-.1-.5-.2l-3.3-3.3c-.3-.3-.3-.8 0-1.1.3-.3.8-.3 1.1 0l2.7 2.7 2.7-2.7c.3-.3.8-.3 1.1 0 .3.3.3.8 0 1.1l-3.2 3.2c-.2.2-.4.3-.6.3Z"></path></svg>
    <svg class="mr-1 text-sky-500" aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor"><path d="M.513 1.513A1.75 1.75 0 0 1 1.75 1h3.5c.55 0 1.07.26 1.4.7l.9 1.2a.25.25 0 0 0 .2.1H13a1 1 0 0 1 1 1v.5H2.75a.75.75 0 0 0 0 1.5h11.978a1 1 0 0 1 .994 1.117L15 13.25A1.75 1.75 0 0 1 13.25 15H1.75A1.75 1.75 0 0 1 0 13.25V2.75c0-.464.184-.91.513-1.237Z"></path></svg>
    <span>models</span>
  </div>
<div>
<div class="ml-6 flex items-center text-base leading-8">
  <svg class="mr-1 text-slate-600 inline-block select-none align-text-bottom overflow-visible" aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg>
  <span>phi-4.Q4_K_M.gguf</span>
</div>
<div class="ml-6 flex items-center text-base leading-8">
  <svg class="mr-1 text-slate-600 inline-block select-none align-text-bottom overflow-visible" aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg>
  <span>gemma-3-27b-it-qat-q4_0-gguf</span>
</div>
<div class="ml-6 flex items-center text-base leading-8">
  <svg class="mr-1 text-slate-600 inline-block select-none align-text-bottom overflow-visible" aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg>
  <span>mistral-small-3.1-24b-instruct-2503-q8_0.gguf</span>
</div>
</div>
</div>
<div>
<div class="ml-6 flex items-center text-base leading-8">
  <svg class="mr-1 text-slate-600 inline-block select-none align-text-bottom overflow-visible" aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg>
  <span>docker-compose.yml</span>
</div>
</div>
</div>
<p>You'll be able to run and test them with:</p>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>docker compose up</p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<p>This will launch 3 container instances of llama-server configured to run different models accessible via an <a href="https://platform.openai.com/docs/api-reference/chat">OpenAI compatible API</a> on ports <code>8000</code>, <code>8001</code> and <code>8002</code> which you can test using llama-server's Chat Web UI.</p>
<h3 id="dedicated-gpus">Dedicated GPUs<a class="header-anchor" href="javascript:;" onclick="location.hash='#dedicated-gpus'" aria-label="Permalink">&ZeroWidthSpace;</a></h3>
<p>Docker containers can also be configured to run llama-server on different dedicated GPUs,
identified by their GPU index:</p>
<pre><code class="language-yml">- driver: nvidia
  device_ids: ['0'] # Assign to GPU 0
  capabilities: [gpu]
</code></pre>
<h2 id="systemd-services">Systemd Services<a class="header-anchor" href="javascript:;" onclick="location.hash='#systemd-services'" aria-label="Permalink">&ZeroWidthSpace;</a></h2>
<p>You can trade hosting flexibility to squeeze an extra ounce of performance and run without the overhead of a container by running a compiled llama-server natively by cloning llama.cpp repo:</p>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>git clone <a href="https://github.com/ggml-org/llama.cpp">https://github.com/ggml-org/llama.cpp</a></p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<p>For NVIDIA GPUs you'll need to install <a href="https://developer.nvidia.com/cuda-toolkit">NVIDIA CUDA Toolkit</a> before running a CUDA optimized llama.cpp build with:</p>
<pre><code class="language-sh">cmake -B build -DGGML_CUDA=ON
cmake --build build --config Release
</code></pre>
<p>If all goes well after a long while you'll get a freshly minted llama-server executable at
<code>/build/bin/llama-server</code> which you can create a managed Systemd service with:</p>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>sudo vi /etc/systemd/system/llama-server-gemma3.service</p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<p>With the configuration of your llama-server service using your preferred model and configuration options, e.g:</p>
<pre><code class="language-ini">[Unit]
Description=Llama Server: Gemma3 27B
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/home/deploy/llama.cpp
Environment=&quot;CUDA_VISIBLE_DEVICES=0&quot;
ExecStart=/home/deploy/llama.cpp/build/bin/llama-server \
  --model /home/deploy/llama.cpp/models/gemma-3-27b-it-qat-q4_0-gguf \
  -ngl 999 --host 0.0.0.0 --port 8080
Restart=on-failure
RestartSec=5s
StandardOutput=file:/home/deploy/llama.cpp/logs/llama-server-gemma3.stdout.log
StandardError=file:/home/deploy/llama.cpp/logs/llama-server-gemma3.stderr.log

[Install]
WantedBy=multi-user.target
</code></pre>
<p>To enable your new systemd service, reload systemd's configuration with:</p>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>systemctl daemon-reload</p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<p>Where you'll now be able to use systemd to start/stop/restart your llama-service with:</p>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>systemctl start llama-server-gemma3</p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<h3 id="typed-open-ai-chat-apis-in-11-languages">Typed Open AI Chat APIs in 11 Languages<a class="header-anchor" href="javascript:;" onclick="location.hash='#typed-open-ai-chat-apis-in-11-languages'" aria-label="Permalink">&ZeroWidthSpace;</a></h3>
<p>Since <a href="https://openai.servicestack.net">AI Server</a> is written in ServiceStack we're able to use
its OpenAI Compatible Chat API DTOs to enable typed integrations in its
<a href="/ai-server/openai-chat-all-languages">11 supported languages</a>.</p>
<h3 id="access-llama-server-from-c">Access llama-server from C#<a class="header-anchor" href="javascript:;" onclick="location.hash='#access-llama-server-from-c'" aria-label="Permalink">&ZeroWidthSpace;</a></h3>
<ol>
<li>Create an empty console application:</li>
</ol>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>dotnet new console</p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<ol start="2">
<li>Add the <strong>ServiceStack.Client</strong> NuGet package:</li>
</ol>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>dotnet add package ServiceStack.Client</p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<ol start="3">
<li>Download AI Server's Typed C# DTOs:</li>
</ol>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p><code>npx get-dtos csharp https://openai.servicestack.net</code></p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<ol start="4">
<li>Call llama-server's OpenAI Chat API from C#:</li>
</ol>
<pre><code class="language-csharp">// Program.cs
using ServiceStack;
using ServiceStack.Text;
using AiServer.ServiceModel;

var client = new JsonApiClient(&quot;https://localhost:8000&quot;);
var result = await client.PostAsync&lt;OpenAiChatResponse&gt;(&quot;/v1/chat/completions&quot;,
    new OpenAiChatCompletion {
        Messages = [
            new () { Role = &quot;user&quot;, Content = &quot;What's the capital of France?&quot; }
        ],
        MaxTokens = 50
    });

result.PrintDump();
</code></pre>
<p>Run the program:</p>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>dotnet run</p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<h3 id="access-llama-server-from-node-or-bun-with-typescript">Access llama-server from <a href="https://nodejs.org">Node</a> or <a href="https://bun.sh">Bun</a> with TypeScript<a class="header-anchor" href="javascript:;" onclick="location.hash='#access-llama-server-from-node-or-bun-with-typescript'" aria-label="Permalink">&ZeroWidthSpace;</a></h3>
<ol>
<li>Add the <code>@servicestack/client</code> client library:</li>
</ol>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>npm install @servicestack/client</p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<ol start="2">
<li>Download AI Server's TypeScript DTOs:</li>
</ol>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p><code>npx get-dtos typescript https://openai.servicestack.net</code></p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<p>Call llama-server with TypeScript DTOs and the generic <code>JsonServiceClient</code></p>
<pre><code class="language-ts">import { JsonServiceClient, Inspect } from &quot;@servicestack/client&quot;
import { OpenAiChatCompletion } from &quot;./dtos&quot;

const client = new JsonServiceClient(&quot;https://localhost:8000&quot;)

const result = await client.postToUrl(&quot;/v1/chat/completions&quot;,
    new OpenAiChatCompletion({
        messages: [
            { role: &quot;user&quot;, content: &quot;What's the capital of France?&quot; }
        ],
        max_tokens: 50
    })
)

Inspect.printDump(result)
</code></pre>
<h2 id="managed-ai-server-gateway">Managed AI Server Gateway<a class="header-anchor" href="javascript:;" onclick="location.hash='#managed-ai-server-gateway'" aria-label="Permalink">&ZeroWidthSpace;</a></h2>
<p>If your organization needs to maintain a number of AI integrations you may want to consider
running them behind a Managed AI Gateway so that your App's only need to be configured to use a
single endpoint, abstracting away all the complexity of managing multiple AI Providers,
API Key managment and monitoring behind a single location.</p>
<h3 id="open-source-ai-server">Open Source AI Server<a class="header-anchor" href="javascript:;" onclick="location.hash='#open-source-ai-server'" aria-label="Permalink">&ZeroWidthSpace;</a></h3>
<p>To support this use-case we're developing <a href="https://openai.servicestack.net">AI Server</a> - an OSS self-hosted managed gateway that our production AI Applications utilize for all their AI requirements.</p>
<p>AI Server allows you to orchestrate your systems AI requests through a single self-hosted application to control what AI Providers App's should use without impacting their client integrations. It serves as a private gateway to process LLM, AI, and Media Transformations, dynamically delegating tasks across multiple providers.</p>
<p><a href="https://openai.servicestack.net"><img src="/img/pages/ai-server/overview.svg" alt="" /></a></p>
<lite-youtube class="w-full mx-4 my-4" width="560" height="315" videoid="Ojo80oFQte8" playlabel="AI Server" style="background-image:url('https://img.youtube.com/vi/Ojo80oFQte8/maxresdefault.jpg')"></lite-youtube>
<p>Benefits include:</p>
<ul>
<li><strong>Unified AI Gateway</strong> - Centralized management, load balance and monitor AI usage</li>
<li><strong>Multi Providers</strong> - Manage multiple self-hosted llama-server/Ollama instances or API Hosted LLMs (e.g. OpenAI, Anthropic, Mistral AI, Google, OpenRouter, Groq)</li>
<li><strong>Load Balancing</strong> - Delegate requests across multiple providers hosting same model</li>
<li><strong>Developer UX</strong> - Simple Typed AI access to developer friendly APIs
in 11 different languages supporting <strong>Synchronous</strong>, <strong>Queued</strong> and <strong>Web Callback</strong> integrations</li>
<li><strong>Secure access</strong> - Only allow access from Auhtorized Apps using simple API keys</li>
<li><strong>Analytics</strong> - Observe and monitor your Organizations AI Usage</li>
<li><strong>Background Jobs</strong> - Monitor executing AI requests in real-time</li>
<li><strong>Audit History</strong> - Access previous AI Request/Responses in monthly archivable DBs</li>
</ul>
<h3 id="install">Install<a class="header-anchor" href="javascript:;" onclick="location.hash='#install'" aria-label="Permalink">&ZeroWidthSpace;</a></h3>
<p>AI Server can be installed on Linux, macOS or WSL/Windows with Docker</p>
<ol>
<li>Clone the Repository</li>
</ol>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>git clone <a href="https://github.com/ServiceStack/ai-server">https://github.com/ServiceStack/ai-server</a></p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<ol start="2">
<li>Run the Installer</li>
</ol>
<div class="not-prose sh-copy cp flex cursor-pointer mb-3" onclick="copy(this)">
                <div class="flex-grow bg-gray-800">
                    <div class="pl-4 py-1 pb-1.5 align-middle whitespace-pre text-base text-gray-100"><p>cd ai-server &amp;&amp; cat install.sh | bash</p>
</div>
                    </div>
                <div class="flex">
                    <div class="bg-green-600 text-white p-1.5 pb-0">
                        <svg class="copied w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <svg class="nocopy w-6 h-6" title="copy" fill='none' stroke='white' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'>
                            <path stroke-linecap='round' stroke-linejoin='round' stroke-width='1' d='M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4.586a1 1 0 01.707.293l4.414 4.414a1 1 0 01.293.707V15a2 2 0 01-2 2h-2M8 7H6a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2v-2'></path>
                        </svg>
                    </div>
                </div>
            </div>
<p><ascii-cinema src="https://docs.servicestack.net/pages/ai-server/ai-server-install.cast"
loop="true" poster="npt:00:21" theme="dracula" rows="12" /></p>
<p>This will launch a self-hosted instance of AI Server at: <code>https://localhost:5006</code> where you'll be able to Sign In with your chosen Admin password at installation and access AI Server's Admin UI at:</p>
<div class="not-prose">
  <h3 class="text-4xl text-center text-indigo-800 pb-3">
    <span class="text-gray-300">https://localhost:5006</span>/admin
  </h3>
</div>
<p><img src="/img/pages/ai-server/admin-dashboard.webp" alt="" /></p>
<h2 id="registering-llama-server-endpoints">Registering llama-server endpoints<a class="header-anchor" href="javascript:;" onclick="location.hash='#registering-llama-server-endpoints'" aria-label="Permalink">&ZeroWidthSpace;</a></h2>
<p>To let AI Server know about your new llama-server instances create a new <strong>AI Provider</strong> with the <strong>Custom</strong> AI Provider type to register an OpenAI Chat compatible endpoint, e.g:</p>
<p><a href="/ai-server/"><img src="/img/pages/ai-server/custom-openai-provider.webp" alt="" /></a></p>
<p>As llama-server is only configured to serve a single model it can configured with any model name as it's ignored by llama-server but used by AI Server to route AI requests for that model to the custom AI Provider instance which you can try in the <a href="/ai-server/chat">Chat UI</a>:</p>
<p><a href="/ai-server/chat"><img src="/img/pages/ai-server/custom-openai-provider-chat.webp" alt="" /></a></p>
<h2 id="create-api-keys-for-your-apps">Create API Keys for your Apps<a class="header-anchor" href="javascript:;" onclick="location.hash='#create-api-keys-for-your-apps'" aria-label="Permalink">&ZeroWidthSpace;</a></h2>
<p>After testing the llama-server instance is working with the Chat UI it's time to create API Keys
for all your Apps so they can access AI Servers APIs with the <a href="/auth/admin-apikeys#api-keys-admin-ui">API Keys UI</a>:</p>
<p><img src="/img/pages/ai-server/admin-apikeys.webp" alt="" /></p>
<p>It's recommended to use a different API Key per App so they can be monitored and analyzed separately.</p>
<p>With a valid API Key in hand your App's can use AI Server's DTOs with ServiceStack generic
service clients to enable typed integrations in <a href="/ai-server/openai-chat-all-languages">11 different languages</a>.</p>
<h3 id="synchronous-usage-example">Synchronous Usage Example<a class="header-anchor" href="javascript:;" onclick="location.hash='#synchronous-usage-example'" aria-label="Permalink">&ZeroWidthSpace;</a></h3>
<p>Here's an example of Synchronous Usage in C#:</p>
<pre><code class="language-csharp">var client = new JsonApiClient(&quot;https://localhost:5006&quot;) { 
  BearerToken = Environment.GetEnvironmentVariable(&quot;AI_SERVER_API_KEY&quot;)
};

var response = await client.PostAsync(new OpenAiChatCompletion {
    Model = &quot;phi4.gguf&quot;,
    Messages =
    [
      new() { Role = &quot;system&quot;, Content = &quot;You are a helpful AI assistant&quot; },
      new() { Role = &quot;user&quot;, Content = &quot;How do LLMs work?&quot; }
    ],
    MaxTokens = 50
});
var answer = response.Choices[0].Message.Content;
</code></pre>
<h3 id="queued-open-ai-chat-completion">Queued Open AI Chat Completion<a class="header-anchor" href="javascript:;" onclick="location.hash='#queued-open-ai-chat-completion'" aria-label="Permalink">&ZeroWidthSpace;</a></h3>
<p>Alternatively, you can call the same endpoint asynchronously which will queue the request for processing then check the status of the request and download the response when it's ready.</p>
<pre><code class="language-csharp">var response = await client.PostAsync(new QueueOpenAiChatCompletion {
  Request = new() {
    Model = &quot;phi4.gguf&quot;,
      Messages =
      [
        new() { Role = &quot;system&quot;, Content = &quot;You are a helpful AI assistant&quot; },
        new() { Role = &quot;user&quot;, Content = &quot;How do LLMs work?&quot; }
      ],
      MaxTokens = 50
    },
});

// Poll for Job Completion Status
GetOpenAiChatStatusResponse status = new();
while (status.JobState is 
  BackgroundJobState.Started or BackgroundJobState.Queued)
{
    status = await client.GetAsync(new GetOpenAiChatStatus { 
      RefId = response.RefId 
    });
    await Task.Delay(1000);
}

var answer = status.Result.Choices[0].Message.Content;
</code></pre>
<h3 id="replyto-callback-chat-completion">ReplyTo Callback Chat Completion<a class="header-anchor" href="javascript:;" onclick="location.hash='#replyto-callback-chat-completion'" aria-label="Permalink">&ZeroWidthSpace;</a></h3>
<p>A more reliable Application integration pattern is to provide a <code>ReplyTo</code> callback URL to get notified of the response when it's completed, e.g:</p>
<pre><code class="language-csharp">var response = await client.PostAsync(new QueueOpenAiChatCompletion {
  Request = new() {
    Model = &quot;phi4.gguf&quot;,
      Messages =
      [
        new() { Role = &quot;system&quot;, Content = &quot;You are a helpful AI assistant&quot; },
        new() { Role = &quot;user&quot;, Content = &quot;How do LLMs work?&quot; }
      ],
      MaxTokens = 50
    },
    ReplyTo = &quot;https://localhost:5001/api/QueueOpenAiChatResponse&quot;
});
</code></pre>
<p>This enables a push notification integration where your response is not coupled to the client making the request and polling for the response. It's a more robust solution as the notification is handled by a managed background job with retries so that App's are still able to get notified of responses after deployments.</p>
</div>

                <div class="not-prose"></div>
                
                    <div class="not-prose py-8">
                        <a class="text-slate-500 font-semibold hover:text-indigo-600 flex items-center" href="https://github.com/ServiceStack/docs.servicestack.net/blob/main/MyApp/_pages/ai-server/llama-server.md" target="_blank" rel="noopener noreferrer">
                            Edit this page on GitHub<svg class="ml-1 inline-block w-4 h-4" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" data-v-1ed99556=""><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg>
                        </a>
                    </div>

                    <div class="not-prose my-20">
                                <nav class="flex items-center justify-between border-t border-gray-200 dark:border-gray-700 px-4 sm:px-0">
                                    <div class="-mt-px flex w-0 flex-1">
                                            <a href="/ai-server/ollama" class="inline-flex items-center border-t-2 border-transparent pt-4 pr-1 text-sm font-medium text-gray-500 hover:border-gray-300 dark:hover:border-gray-600 hover:text-gray-700 dark:hover:text-gray-200">
                                                <!-- Heroicon name: mini/arrow-long-left -->
                                                <svg class="mr-3 h-5 w-5 text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true">
                                                    <path fill-rule="evenodd" d="M18 10a.75.75 0 01-.75.75H4.66l2.1 1.95a.75.75 0 11-1.02 1.1l-3.5-3.25a.75.75 0 010-1.1l3.5-3.25a.75.75 0 111.02 1.1l-2.1 1.95h12.59A.75.75 0 0118 10z" clip-rule="evenodd"></path>
                                                </svg>
                                                Ollama
                                            </a>
                                    </div>
                                    <div class="hidden md:-mt-px md:flex"></div>
                                    <div class="-mt-px flex w-0 flex-1 justify-end">
                                            <a href="/ai-server/comfy-extension" class="inline-flex items-center border-t-2 border-transparent pt-4 pl-1 text-sm font-medium text-gray-500 hover:border-gray-300 dark:hover:border-gray-600 hover:text-gray-700 dark:hover:text-gray-200">
                                                ComfyUI Agent
                                                <!-- Heroicon name: mini/arrow-long-right -->
                                                <svg class="ml-3 h-5 w-5 text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true">
                                                    <path fill-rule="evenodd" d="M2 10a.75.75 0 01.75-.75h12.59l-2.1-1.95a.75.75 0 111.02-1.1l3.5 3.25a.75.75 0 010 1.1l-3.5 3.25a.75.75 0 11-1.02-1.1l2.1-1.95H2.75A.75.75 0 012 10z" clip-rule="evenodd"></path>
                                                </svg>
                                            </a>
                                    </div>
                                </nav>
                    </div>
            </div>
                
                <div class="docmap hidden 2xl:block flex-none w-64 pl-8 mr-8">
                    <div class="fixed bg-white dark:bg-black flex flex-col overflow-y-auto pt-10 px-8 pb-6" style="height:calc(100vh - 50px);">
                        <div>
                            <h5 class="text-slate-900 font-semibold mb-4 text-sm leading-6 dark:text-slate-100">
                                On This Page
                            </h5>
                            <ul class="text-slate-700 text-sm leading-6">
                                    <li class="group text-gray-800 hover:text-gray-900">
                                        <span v-hash="'#enter-llama-server-the-production-workhorse'" data-id="enter-llama-server-the-production-workhorse" class="cursor-pointer font-medium block text-sm transform transition-colors duration-200 py-2">
                                            Enter llama-server: The Production workhorse
                                        </span>
                                    </li>
                                    <li class="group text-gray-800 hover:text-gray-900">
                                        <span v-hash="'#hosting-llama-server-with-docker'" data-id="hosting-llama-server-with-docker" class="cursor-pointer font-medium block text-sm transform transition-colors duration-200 py-2">
                                            Hosting llama-server with Docker
                                        </span>
                                            <ul class="ml-4">
                                                    <li data-id="docker-compose" class="text-gray-500 hover:text-gray-900">
                                                        <span v-hash="'#docker-compose'" class="cursor-pointer flex text-sm transform transition-colors duration-200 py-2">
                                                            <svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>
                                                            Docker compose
                                                        </span>
                                                    </li>
                                                    <li data-id="dedicated-gpus" class="text-gray-500 hover:text-gray-900">
                                                        <span v-hash="'#dedicated-gpus'" class="cursor-pointer flex text-sm transform transition-colors duration-200 py-2">
                                                            <svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>
                                                            Dedicated GPUs
                                                        </span>
                                                    </li>
                                            </ul>
                                    </li>
                                    <li class="group text-gray-800 hover:text-gray-900">
                                        <span v-hash="'#systemd-services'" data-id="systemd-services" class="cursor-pointer font-medium block text-sm transform transition-colors duration-200 py-2">
                                            Systemd Services
                                        </span>
                                            <ul class="ml-4">
                                                    <li data-id="typed-open-ai-chat-apis-in-11-languages" class="text-gray-500 hover:text-gray-900">
                                                        <span v-hash="'#typed-open-ai-chat-apis-in-11-languages'" class="cursor-pointer flex text-sm transform transition-colors duration-200 py-2">
                                                            <svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>
                                                            Typed Open AI Chat APIs in 11 Languages
                                                        </span>
                                                    </li>
                                                    <li data-id="access-llama-server-from-c" class="text-gray-500 hover:text-gray-900">
                                                        <span v-hash="'#access-llama-server-from-c'" class="cursor-pointer flex text-sm transform transition-colors duration-200 py-2">
                                                            <svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>
                                                            Access llama-server from C#
                                                        </span>
                                                    </li>
                                                    <li data-id="access-llama-server-from-node-or-bun-with-typescript" class="text-gray-500 hover:text-gray-900">
                                                        <span v-hash="'#access-llama-server-from-node-or-bun-with-typescript'" class="cursor-pointer flex text-sm transform transition-colors duration-200 py-2">
                                                            <svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>
                                                            Access llama-server from 
                                                        </span>
                                                    </li>
                                            </ul>
                                    </li>
                                    <li class="group text-gray-800 hover:text-gray-900">
                                        <span v-hash="'#managed-ai-server-gateway'" data-id="managed-ai-server-gateway" class="cursor-pointer font-medium block text-sm transform transition-colors duration-200 py-2">
                                            Managed AI Server Gateway
                                        </span>
                                            <ul class="ml-4">
                                                    <li data-id="open-source-ai-server" class="text-gray-500 hover:text-gray-900">
                                                        <span v-hash="'#open-source-ai-server'" class="cursor-pointer flex text-sm transform transition-colors duration-200 py-2">
                                                            <svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>
                                                            Open Source AI Server
                                                        </span>
                                                    </li>
                                                    <li data-id="install" class="text-gray-500 hover:text-gray-900">
                                                        <span v-hash="'#install'" class="cursor-pointer flex text-sm transform transition-colors duration-200 py-2">
                                                            <svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>
                                                            Install
                                                        </span>
                                                    </li>
                                            </ul>
                                    </li>
                                    <li class="group text-gray-800 hover:text-gray-900">
                                        <span v-hash="'#registering-llama-server-endpoints'" data-id="registering-llama-server-endpoints" class="cursor-pointer font-medium block text-sm transform transition-colors duration-200 py-2">
                                            Registering llama-server endpoints
                                        </span>
                                    </li>
                                    <li class="group text-gray-800 hover:text-gray-900">
                                        <span v-hash="'#create-api-keys-for-your-apps'" data-id="create-api-keys-for-your-apps" class="cursor-pointer font-medium block text-sm transform transition-colors duration-200 py-2">
                                            Create API Keys for your Apps
                                        </span>
                                            <ul class="ml-4">
                                                    <li data-id="synchronous-usage-example" class="text-gray-500 hover:text-gray-900">
                                                        <span v-hash="'#synchronous-usage-example'" class="cursor-pointer flex text-sm transform transition-colors duration-200 py-2">
                                                            <svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>
                                                            Synchronous Usage Example
                                                        </span>
                                                    </li>
                                                    <li data-id="queued-open-ai-chat-completion" class="text-gray-500 hover:text-gray-900">
                                                        <span v-hash="'#queued-open-ai-chat-completion'" class="cursor-pointer flex text-sm transform transition-colors duration-200 py-2">
                                                            <svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>
                                                            Queued Open AI Chat Completion
                                                        </span>
                                                    </li>
                                                    <li data-id="replyto-callback-chat-completion" class="text-gray-500 hover:text-gray-900">
                                                        <span v-hash="'#replyto-callback-chat-completion'" class="cursor-pointer flex text-sm transform transition-colors duration-200 py-2">
                                                            <svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>
                                                            ReplyTo Callback Chat Completion
                                                        </span>
                                                    </li>
                                            </ul>
                                    </li>
                            </ul>
                        </div>
                    </div>
                </div>
                
        </div>
    </div>    
</div>

<script>
//doc instructions
if (document.querySelector('.hide-title')) {
    const el = document.querySelector('#doc section h1') 
    if (el) el.style.display='none'
}
</script>


<script type="module">
import { ref } from "vue"
import { mount } from "app.mjs"


    const App = {
        setup() {
            function nav(url) {
                window.open(url)
            }
            return { nav }
        }
    }
    
const Sidebar = {
    setup() {
        const open = ref(true)
        return { open }
    }
}

mount('#doc', App)
mount('#sidebar', Sidebar)
</script>

<script src="/lib/js/highlight.js"></script>
<script>hljs.highlightAll()</script>
<script src="/lib/js/lite-yt-embed.js"></script>
<script src="/mjs/docs.mjs" type="module"></script>


    </main>
</div>

<script type="module">
import { init } from "app.mjs"
init()
</script>





</body>
</html>